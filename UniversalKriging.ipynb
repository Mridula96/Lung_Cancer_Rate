{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6179503",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pykrige.uk import UniversalKriging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "import folium\n",
    "from tqdm import tqdm\n",
    "from folium.plugins import MarkerCluster\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from branca.colormap import LinearColormap\n",
    "from IPython.display import display\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Set environment variable for OpenMP\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c75ac043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3143\n",
      "\n",
      "    FIPS   Parish   Latitude  Longitude    Income  Insurance    PM 2.5  \\\n",
      "0  1001  Autauga  32.535142 -86.642900  0.308876   0.828652  0.619048   \n",
      "1  1003  Baldwin  30.727825 -87.722745  0.343421   0.772472  0.455782   \n",
      "2  1005  Barbour  31.870090 -85.391068  0.151268   0.719101  0.578231   \n",
      "3  1007     Bibb  32.998376 -87.126814  0.231939   0.755618  0.605442   \n",
      "4  1009   Blount  33.980871 -86.567006  0.251355   0.707865  0.591837   \n",
      "\n",
      "    Poverty   Smoking  LungCancerRate  \n",
      "0  0.161165  0.424242        0.311271  \n",
      "1  0.135922  0.478788        0.288991  \n",
      "2  0.403883  0.515152        0.338794  \n",
      "3  0.316505  0.590909        0.412844  \n",
      "4  0.198058  0.578788        0.333552  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_excel(\"Dataset.xlsx\")\n",
    "\n",
    "row_count = data.shape[0]\n",
    "print(\"Number of rows:\", row_count)\n",
    "\n",
    "print(\"\\n\", data.head(5))\n",
    "\n",
    "# Extract coordinates and variables\n",
    "X, Y = data['Longitude'].values, data['Latitude'].values\n",
    "Z = data['LungCancerRate'].values\n",
    "Z_positive = np.where(Z == 0, 0.01, Z)\n",
    "Z_log = np.log1p(Z_positive)\n",
    "\n",
    "# Prepare additional variables\n",
    "additional_vars = ['Smoking', 'Poverty', 'PM 2.5', 'Insurance', 'Income']\n",
    "additional_data = data[additional_vars].values\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = train_test_split(np.column_stack((X, Y, Z_log, additional_data)), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df61c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing UniversalKriging...\n"
     ]
    }
   ],
   "source": [
    "# Perform UniversalKriging\n",
    "def perform_kriging(x, y):\n",
    "    try:\n",
    "        pred, _ = uk_model.execute('points', np.array([x]), np.array([y]))\n",
    "        return pred[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error at point ({x}, {y}): {str(e)}\")\n",
    "        return np.nan\n",
    "\n",
    "print(\"Performing UniversalKriging...\")\n",
    "uk_model = UniversalKriging(train_data[:, 0], train_data[:, 1], train_data[:, 2], variogram_model='spherical', drift_terms=['regional_linear'])\n",
    "\n",
    "# Use parallel processing for kriging\n",
    "uk_all_predictions = Parallel(n_jobs=-1)(delayed(perform_kriging)(x, y) for x, y in tqdm(zip(X, Y), total=len(X), desc=\"UK Progress\"))\n",
    "uk_all_predictions = np.array(uk_all_predictions)\n",
    "print(\"UniversalKriging completed.\")\n",
    "\n",
    "# Convert predictions back to original scale and add to DataFrame\n",
    "data['UK_Predicted_LungCancerRate'] = np.expm1(uk_all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error metrics\n",
    "uk_mae = mean_absolute_error(data['LungCancerRate'], data['UK_Predicted_LungCancerRate'])\n",
    "uk_r2 = r2_score(data['LungCancerRate'], data['UK_Predicted_LungCancerRate'])\n",
    "\n",
    "# Display error metrics\n",
    "print(f\"Universal Kriging - MAE: {uk_mae:.4f}\")\n",
    "print(f\"Universal Kriging - R-squared: {uk_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f30f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "feature_column = 'UK_Predicted_LungCancerRate'\n",
    "feature_name = 'Predicted Lung Cancer Rate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c719d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def perform_clustering(data, feature_column):\n",
    "    features = data[[feature_column]].values\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Elbow method for optimal k\n",
    "    visualizer = KElbowVisualizer(KMeans(n_init=10, random_state=42), k=(2, 20), metric='distortion', timings=False)\n",
    "    visualizer.fit(features_scaled)\n",
    "    optimal_k = visualizer.elbow_value_\n",
    "    \n",
    "    print(\"Optimal K for clustering: \", optimal_k)\n",
    "    \n",
    "    # Perform clustering\n",
    "    kmeans = KMeans(n_clusters=optimal_k, n_init=10, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "    return optimal_k, cluster_labels\n",
    "\n",
    "# Perform clustering\n",
    "optimal_k, cluster_labels = perform_clustering(data, feature_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd131c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_map(data, feature_column, feature_name, cluster_labels):\n",
    "    data[f'Cluster_{feature_name}'] = cluster_labels\n",
    "    optimal_k = len(np.unique(cluster_labels))\n",
    "    \n",
    "    m = folium.Map(location=[data['Latitude'].mean(), data['Longitude'].mean()], zoom_start=4)\n",
    "    cluster_colors = ['red', 'blue', 'green', 'purple', 'orange', 'yellow', 'pink', 'cyan', 'brown', 'magenta']\n",
    "    color_dict = {i: cluster_colors[i % len(cluster_colors)] for i in range(optimal_k)}\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row['Latitude'], row['Longitude']],\n",
    "            radius=5,\n",
    "            popup=f\"Parish: {row['Parish']}<br>Cluster: {row[f'Cluster_{feature_name}']}<br>{feature_name}: {row[feature_column]:.3f}<br>\",\n",
    "            color=color_dict[row[f'Cluster_{feature_name}']],\n",
    "            fill=True,\n",
    "            fillColor=color_dict[row[f'Cluster_{feature_name}']],\n",
    "            fillOpacity=0.7,\n",
    "            weight=2\n",
    "        ).add_to(m)\n",
    "    \n",
    "    display(m)\n",
    "    \n",
    "# Create and display the cluster map\n",
    "create_cluster_map(data, feature_column, feature_name, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def cluster_wise_analysis(data, feature_name, optimal_k, additional_vars):\n",
    "    for cluster in range(optimal_k):\n",
    "        cluster_data = data[data[f'Cluster_{feature_name}'] == cluster]\n",
    "        n_obs = len(cluster_data)\n",
    "        \n",
    "        if n_obs < 10:\n",
    "            print(f\"\\nCluster {cluster} has too few points, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nCluster {cluster} - Number of observations: {n_obs}\")\n",
    "        \n",
    "        # Prepare the design matrix\n",
    "        Z_cluster = np.log1p(cluster_data['UK_Predicted_LungCancerRate'].values)\n",
    "        X_additional = cluster_data[additional_vars].values\n",
    "        X_additional_scaled = StandardScaler().fit_transform(X_additional)\n",
    "        X_with_drift = np.column_stack((np.ones(n_obs), X_additional_scaled))\n",
    "        \n",
    "        # Perform calculations\n",
    "        mse = np.mean((Z_cluster - np.mean(Z_cluster))**2) \n",
    "        p = X_with_drift.shape[1]\n",
    "        dof = n_obs - p\n",
    "        \n",
    "        # Covariance matrix calculation\n",
    "        cov_matrix = np.linalg.inv(X_with_drift.T @ X_with_drift + np.eye(p) * 1e-8) * mse\n",
    "        std_errors = np.sqrt(np.diag(cov_matrix))\n",
    "        \n",
    "        # Coefficients\n",
    "        coefficients = np.linalg.lstsq(X_with_drift, Z_cluster, rcond=None)[0] \n",
    "        \n",
    "        # T-statistics and P-values calculation\n",
    "        t_stats = coefficients / std_errors\n",
    "        p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), df=dof))\n",
    "        std_coefficients = coefficients[1:] * np.std(X_with_drift[:, 1:], axis=0)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nVariable Statistics:\")\n",
    "        print(\"{:<15} {:<15} {:<15} {:<15} {:<15}\".format(\"Variable\", \"Coefficient\", \"Std Error\", \"T-stat\", \"P-value\"))\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        variable_names = ['Intercept'] + additional_vars\n",
    "        for name, coef, std_err, t_stat, p_val in zip(variable_names, coefficients, std_errors, t_stats, p_values):\n",
    "            print(\"{:<15} {:<15.6f} {:<15.6f} {:<15.6f} {:<15.6f}\".format(name, coef, std_err, t_stat, p_val))\n",
    "\n",
    "# Perform cluster-wise analysis\n",
    "cluster_wise_analysis(data, feature_name, optimal_k, additional_vars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
